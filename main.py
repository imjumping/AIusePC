# main.py - AIusePC ä¸»ç¨‹åº
# è®©è®­ç»ƒå¥½çš„ AI æ§åˆ¶ä½ çš„é¼ æ ‡ï¼
# å®‰å…¨ç¬¬ä¸€ï¼šåŒå‡» ESC é€€å‡º
# GitHub: github.com/imjumping

import torch
import cv2
import numpy as np
import pyautogui
import time
from pynput import keyboard, mouse
import os

# ================================
# é…ç½®
# ================================
MODEL_PATH = "model/model.bin"
SCREEN_W, SCREEN_H = 2160, 1440  # ä¿®æ”¹ä¸ºä½ çš„åˆ†è¾¨ç‡
INPUT_SIZE = 224
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# åŠ è½½æ¨¡å‹ï¼ˆå¿…é¡»å…ˆå®šä¹‰æ¨¡å‹ç»“æ„ï¼‰
from model import MousePredictor
model = MousePredictor().to(DEVICE)
try:
    model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))
    model.eval()
    print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ: {MODEL_PATH}")
except Exception as e:
    print(f"âŒ åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
    exit(1)

# å®æ—¶æˆªå›¾å·¥å…·ï¼ˆç”¨ mss æ›´å¿«ï¼Œè¿™é‡Œç”¨ pyautogui ç®€å•å…¼å®¹ï¼‰
def capture_screen():
    img = pyautogui.screenshot()
    frame = np.array(img)
    frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
    return cv2.resize(frame, (INPUT_SIZE, INPUT_SIZE))

# å®‰å…¨é€€å‡ºæœºåˆ¶
exit_count = 0
def on_press(key):
    global exit_count
    try:
        if key == keyboard.Key.esc:
            exit_count += 1
            if exit_count >= 2:
                print("\nğŸ›‘ åŒå‡» ESC æ£€æµ‹åˆ°ï¼Œå®‰å…¨é€€å‡ºï¼")
                os._exit(0)
        else:
            exit_count = 0
    except:
        pass

# å¯åŠ¨é”®ç›˜ç›‘å¬
listener = keyboard.Listener(on_press=on_press)
listener.start()
print("ğŸ® AI å·²å¯åŠ¨ï¼")
print("ğŸ’¡ æ“ä½œè¯´æ˜ï¼š")
print("   - AI å°†è‡ªåŠ¨æ§åˆ¶é¼ æ ‡")
print("   - âš ï¸ å¦‚æœè¡Œä¸ºå¼‚å¸¸ï¼Œç«‹åˆ»è¿æŒ‰ä¸¤æ¬¡ ESC é€€å‡ºï¼")
print("   - æœ¬ç¨‹åºä»…ä¾›å¨±ä¹ï¼Œåˆ‡å‹¿æ—¥å¸¸ä½¿ç”¨ï¼\n")
print("ç¨‹åºå°†åœ¨äº”ç§’åå¼€å§‹å¯åŠ¨ï¼")
time.sleep(5)
# ================================
# ä¸»å¾ªç¯
# ================================
try:
    with torch.no_grad():
        while True:
            # 1. æˆªå›¾
            frame = capture_screen()
            frame_tensor = torch.tensor(frame).permute(2, 0, 1).float() / 255.0
            frame_tensor = frame_tensor.unsqueeze(0).to(DEVICE)

            # 2. é¢„æµ‹
            pred_pos, pred_click = model(frame_tensor)
            x_norm, y_norm = pred_pos[0].cpu().numpy()
            is_click = pred_click[0].item() > 0.5  # é˜ˆå€¼ 0.5

            # 3. è½¬æ¢ä¸ºå±å¹•åæ ‡
            x = int(x_norm * SCREEN_W)
            y = int(y_norm * SCREEN_H)

            # 4. ç§»åŠ¨é¼ æ ‡
            pyautogui.moveTo(x, y)

            # 5. æ˜¯å¦ç‚¹å‡»
            if is_click:
                pyautogui.click()

            # 6. æ§åˆ¶å¸§ç‡ï¼ˆçº¦ 10 FPSï¼‰
            time.sleep(0.1)

except KeyboardInterrupt:
    print("\nğŸ‘‹ ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­ã€‚")
except Exception as e:
    print(f"âŒ è¿è¡Œæ—¶é”™è¯¯: {e}")

finally:
    listener.stop()